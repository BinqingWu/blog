



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <link rel="canonical" href="https://github.com/SkrLamei/blog/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GNN/">
      
      
        <meta name="author" content="Lamei">
      
      <link rel="shortcut icon" href="../../images/favicon.jpg">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.5.13">
    
    
      
        <title>图神经基础知识 - Lamei's Blog</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.077507d7.min.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ff0a5ce4.min.css">
      
      
        
        
        <meta name="theme-color" content="#000000">
      
    
    
    
      
    
    
    
    
      
        
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-188482877-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="black" data-md-color-accent="">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://github.com/SkrLamei/blog" title="Lamei's Blog" class="md-header-nav__button md-logo" aria-label="Lamei's Blog">
      
  <img src="../../images/favicon.jpg" alt="logo">

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Lamei's Blog
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              图神经基础知识
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/SkrLamei/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Lamei
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://github.com/SkrLamei/blog" title="Lamei's Blog" class="md-nav__button md-logo" aria-label="Lamei's Blog">
      
  <img src="../../images/favicon.jpg" alt="logo">

    </a>
    Lamei's Blog
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/SkrLamei/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Lamei
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="个人介绍" class="md-nav__link">
      个人介绍
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      AI基础知识
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="AI基础知识" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon"></span>
        AI基础知识
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../AI%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%8D%8F%E6%96%B9%E5%B7%AE%E5%92%8CPCA/" title="协方差与PCA" class="md-nav__link">
      协方差与PCA
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../AI%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%8C%83%E6%95%B0%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96/" title="范数与正则化" class="md-nav__link">
      范数与正则化
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      图神经网络
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="图神经网络" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon"></span>
        图神经网络
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        图神经基础知识
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" title="图神经基础知识" class="md-nav__link md-nav__link--active">
      图神经基础知识
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    总览
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    线性代数
  </a>
  
    <nav class="md-nav" aria-label="线性代数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    实对称、正定、半正定、对角矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    奇异值
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    特征值和特征向量
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    对角化
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    图的基本知识
  </a>
  
    <nav class="md-nav" aria-label="图的基本知识">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    邻接矩阵、度矩阵、拉普拉斯算子、拉普拉斯矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    图相关的矩阵规律
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    傅里叶变换
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gnn" class="md-nav__link">
    GNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    图滤波器
  </a>
  
    <nav class="md-nav" aria-label="图滤波器">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    频域角度理解
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    空域角度理解
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    频域与空域比较
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    图卷积
  </a>
  
    <nav class="md-nav" aria-label="图卷积">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gcncnn" class="md-nav__link">
    GCN与CNN的比较
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcn" class="md-nav__link">
    GCN与基于手工与基于随机游走的方法的比较
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcn_1" class="md-nav__link">
    GCN是一个低通滤波器
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcn_2" class="md-nav__link">
    GCN的过平滑问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcn_3" class="md-nav__link">
    GCN实战
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      概率相关
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="概率相关" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon"></span>
        概率相关
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E6%A6%82%E7%8E%87%E7%9B%B8%E5%85%B3/ACD/" title="ACD" class="md-nav__link">
      ACD
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E6%A6%82%E7%8E%87%E7%9B%B8%E5%85%B3/GAE/" title="GAE" class="md-nav__link">
      GAE
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E6%A6%82%E7%8E%87%E7%9B%B8%E5%85%B3/NRI/" title="NRI" class="md-nav__link">
      NRI
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E6%A6%82%E7%8E%87%E7%9B%B8%E5%85%B3/VAE/" title="VAE" class="md-nav__link">
      VAE
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E6%A6%82%E7%8E%87%E7%9B%B8%E5%85%B3/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/" title="概率图模型" class="md-nav__link">
      概率图模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E6%A6%82%E7%8E%87%E7%9B%B8%E5%85%B3/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/" title="概率基础" class="md-nav__link">
      概率基础
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    总览
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    线性代数
  </a>
  
    <nav class="md-nav" aria-label="线性代数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    实对称、正定、半正定、对角矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    奇异值
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    特征值和特征向量
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    对角化
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    图的基本知识
  </a>
  
    <nav class="md-nav" aria-label="图的基本知识">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    邻接矩阵、度矩阵、拉普拉斯算子、拉普拉斯矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    图相关的矩阵规律
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    傅里叶变换
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gnn" class="md-nav__link">
    GNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    图滤波器
  </a>
  
    <nav class="md-nav" aria-label="图滤波器">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    频域角度理解
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    空域角度理解
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    频域与空域比较
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    图卷积
  </a>
  
    <nav class="md-nav" aria-label="图卷积">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gcncnn" class="md-nav__link">
    GCN与CNN的比较
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcn" class="md-nav__link">
    GCN与基于手工与基于随机游走的方法的比较
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcn_1" class="md-nav__link">
    GCN是一个低通滤波器
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcn_2" class="md-nav__link">
    GCN的过平滑问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gcn_3" class="md-nav__link">
    GCN实战
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
  
                
                  <a href="https://github.com/SkrLamei/edit/master/docs/图神经网络/GNN.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                <h1 id="_1">图神经基础知识<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<h2 id="_2">总览<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<ul>
<li>线性代数<ul>
<li>正定、半正定、对角、对称矩阵，特征值、特征向量、对角化</li>
</ul>
</li>
<li>图的基本知识<ul>
<li>邻接矩阵、度矩阵、拉普拉斯矩阵</li>
</ul>
</li>
<li>傅里叶变换</li>
<li>图傅里叶变换</li>
<li>图卷积</li>
<li>GNN的优缺点和变式</li>
</ul>
<h2 id="_3">线性代数<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<h3 id="_4"><strong>实对称、正定、半正定、对角矩阵</strong><a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>实对称矩阵：</strong> 如果有 <span class="arithmatex">\(n\)</span> 阶矩阵 <span class="arithmatex">\(A\)</span>，其矩阵的元素都为实数，且矩阵<span class="arithmatex">\(A\)</span>的转置等于其本身（ <span class="arithmatex">\(a_{ij}=a_{ji}\)</span> ），( <span class="arithmatex">\(i\)</span> , <span class="arithmatex">\(j\)</span> 为元素的脚标），则称 <span class="arithmatex">\(A\)</span> 为实对称矩阵。</p>
<ul>
<li>对称矩阵一定有 <span class="arithmatex">\(n\)</span> 个线性无关的特征向量</li>
<li>实对称矩阵都可以对角化</li>
<li>对称矩阵的特征向量相互正交，即所有特征向量构成的矩阵为傅里叶变换</li>
</ul>
</li>
<li>
<p><strong>正定矩阵:</strong> 给定一个大小为<span class="arithmatex">\(n \times n\)</span>的实对称矩阵 <span class="arithmatex">\(A\)</span> ,若对于任意长度为 <span class="arithmatex">\(n\)</span> 的非零向量 <span class="arithmatex">\(x\)</span> ，有 <span class="arithmatex">\(x^TAx &gt; 0\)</span> 恒成立，则矩阵 <span class="arithmatex">\(A\)</span> 是一个正定矩阵。</p>
<ul>
<li>每个正定阵都是可逆的，它的逆也是正定阵</li>
</ul>
</li>
<li>
<p><strong>半正定矩阵:</strong> 给定一个大小为 <span class="arithmatex">\(n \times n\)</span> 的实对称矩阵 <span class="arithmatex">\(A\)</span> ，若对于任意长度为 <span class="arithmatex">\(n\)</span> 的非零向量 <span class="arithmatex">\(x\)</span>，有 <span class="arithmatex">\(x^TAx \geq 0\)</span> 恒成立，则矩阵 <span class="arithmatex">\(A\)</span> 是一个半正定矩阵。</p>
<ul>
<li>半正定矩阵的特征值一定非负</li>
</ul>
</li>
<li>
<p><strong>对角矩阵:</strong> 是一个主对角线之外的元素皆为0的矩阵。</p>
<ul>
<li>对角矩阵在连乘的时候，计算很方便。</li>
</ul>
<div class="arithmatex">\[
A = \left[  
    \begin{array}{cccc}
        a &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; b &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; c &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; d
    \end{array}
    \right]
, A^{100}=\left[
    \begin{array}{cccc}
    a^{100} &amp; 0 &amp; 0 &amp; 0 \\ 
    0 &amp; b^{100} &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; c^{100} &amp; 0 \\ 
    0 &amp; 0 &amp; 0 &amp; d^{100}
    \end{array}
    \right]
\]</div>
</li>
</ul>
<h3 id="_5">奇异值<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p><a href="https://www.cnblogs.com/endlesscoding/p/10033527.html">SVD（奇异值分解）小结</a></p>
<h3 id="_6"><strong>特征值和特征向量</strong><a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<p><span class="arithmatex">\(A\)</span>是一个矩阵（线性变换），<span class="arithmatex">\(x\)</span>是一个向量。若向量<span class="arithmatex">\(x\)</span>经过线性变换<span class="arithmatex">\(A\)</span>后仍和原向量共线，即满足<span class="arithmatex">\(Ax = \lambda x\)</span>，那么，就称<span class="arithmatex">\(x\)</span>为特征向量，<span class="arithmatex">\(\lambda\)</span>为特征值。注意，<span class="arithmatex">\(\lambda\)</span>为标量，即特征向量的长度在该线性变换下缩放的比例，可为负值。  </p>
<ul>
<li>
<p><strong>求解特征值的思路:</strong>   </p>
<div class="arithmatex">\[
\begin{aligned} 
Ax &amp;= \lambda x \\ 
Ax-\lambda Ix &amp;= 0 \\ 
(A-\lambda I)x &amp;= 0
\end{aligned}
\]</div>
<p>如果<span class="arithmatex">\(x\)</span>本身是零向量，等式成立。也就是说，零向量肯定是特征向量。若向量<span class="arithmatex">\(x\)</span>非零，为求解该向量，我们考虑，若一个矩阵与非零向量的乘积为零向量，当且仅当，矩阵代表的变换将空间压缩到更低维度即矩阵非满秩。对应的，该矩阵的行列式为零。因为行列式就是矩阵对应的线性变换对空间的拉伸程度的度量，或者说物体经过变换前后的体积比。特别地，如果矩阵不是满秩的，意味着一个<span class="arithmatex">\(n\)</span>维的空间变换后被压扁了，变成了其中的一个<span class="arithmatex">\(n-1\)</span>维的超平面甚至是维度更低的超直线，所以原来空间中的体积元在变换后体积为0，此时行列式也是0。</p>
<div class="arithmatex">\[
\text{det}(A-\lambda I) = 0
\]</div>
<p>求出<span class="arithmatex">\(\lambda\)</span>后再回代到<span class="arithmatex">\((A-\lambda I)x = 0\)</span>,求出<span class="arithmatex">\(x\)</span>。</p>
</li>
</ul>
<h3 id="_7"><strong>对角化</strong><a class="headerlink" href="#_7" title="Permanent link">&para;</a></h3>
<ul>
<li><span class="arithmatex">\(X^{-1}AX=\Lambda\)</span>,对角化后得到的矩阵为对角矩阵。<span class="arithmatex">\(A\)</span>是原矩阵，<span class="arithmatex">\(X\)</span>是特征向量组成的矩阵</li>
<li><span class="arithmatex">\(X^{-1}AX=\Lambda \Leftrightarrow A = X\Lambda X^{-1}\)</span> </li>
<li>矩阵对角化就是把一组基上的线性变换用另一组基来描述，用后一组基描述时，线性变换只是单纯的伸缩变换,因为是特征向量做基。</li>
<li>实对称矩阵<span class="arithmatex">\(A\)</span>必能对角化。且实对称矩阵<span class="arithmatex">\(A\)</span>对应于不同特征值的特征向量必正交 (相乘为零向量)。若一组正交基内的基向量的模长都是单位长度1，则称这组正交基为标准正交基。</li>
</ul>
<p><span id = "ref" style="font-size:20px">Ref</span></p>
<ol>
<li>
<p><a href="https://www.bilibili.com/video/BV1ys411472E?p=14">3Blue1Brown, 特征向量与特征值</a></p>
</li>
<li>
<p><a href="https://zh.wikipedia.org/wiki/%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F">wiki, 特征值和特征向量</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/44860862">知乎,浅谈「正定矩阵」和「半正定矩阵」</a></p>
</li>
<li>
<p><a href="https://www.zhihu.com/question/26294660">知乎，行列式的意义是什么？</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/34281291">知乎，矩阵对角化与奇异值分解</a></p>
</li>
</ol>
<h2 id="_8">图的基本知识<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h2>
<h3 id="_9"><strong>邻接矩阵、度矩阵、拉普拉斯算子、拉普拉斯矩阵</strong><a class="headerlink" href="#_9" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>邻接矩阵 <span class="arithmatex">\(A\)</span>:</strong> 表示顶点之间相邻关系的矩阵.若<span class="arithmatex">\((v_{i},v_{j})\in E(G)\)</span>，<span class="arithmatex">\(A_ = 1\)</span>，否则<span class="arithmatex">\(A_ = 0\)</span><ul>
<li><span class="arithmatex">\(A^{n}\)</span>的元素 <span class="arithmatex">\(A_{ij}^{n}\)</span> 可以表示由顶点 <span class="arithmatex">\(i\)</span> 到顶点 <span class="arithmatex">\(j\)</span> 长度为 <span class="arithmatex">\(n\)</span> 的径的数目</li>
<li>度数正规化：<span class="arithmatex">\(\hat{A} = D^{-\frac{1}{2}}AD^{\frac{1}{2}}\)</span>, 使得特征值介于<span class="arithmatex">\([-1,1]\)</span>，若第二大的特征值小于1，则图联通(无向图，图连通)。<span id = "" style ="color:red"></li>
</ul>
</li>
<li>
<p><strong>度矩阵 <span class="arithmatex">\(D\)</span>:</strong> 给定一个图<span class="arithmatex">\(G=(V,E)\)</span>与<span class="arithmatex">\(|V|=n\)</span>，<span class="arithmatex">\(G\)</span>的度数矩阵<span class="arithmatex">\(D\)</span>是一个<span class="arithmatex">\(n\times n\)</span>的对角线矩阵，其定义为</p>
<div class="arithmatex">\[
d_{i, j}:=\left\{\begin{array}{cc}
\operatorname{deg}\left(v_{i}\right) &amp; \text { if } i=j \\
0 &amp; \text { otherwise }
\end{array}\right.
\]</div>
<p>其中度数<span class="arithmatex">\(\deg(v_{i})\)</span>为这个顶点上的边的条数。</p>
</li>
<li>
<p><strong>拉普拉斯算子：</strong><span class="arithmatex">\(\Delta f=\sum_{i}\frac{\partial^2{f}}{\partial^2{x}}\)</span>，即非混合二阶偏导数的和。<span class="arithmatex">\(f\)</span>是拉普拉斯算子作用的函数，求函数各向二阶导数再求和，定义为<span class="arithmatex">\(f\)</span>上的拉普拉斯算子。由于图是一种离散数据，那么其拉普拉斯算子必然要进行离散化。</p>
<ul>
<li>
<p>一维</p>
<div class="arithmatex">\[\begin{aligned}
f^{\prime \prime}(x) &amp;=\frac{\partial^{2} f(x)}{\partial^{2} x} \\
&amp;=f^{\prime}(x)-f^{\prime}(x-1)=f(x+1)-f(x)-(f(x)-f(x-1)) \\
&amp;=f(x+1)+f(x-1)-2 f(x) \\
&amp;=[f(x+1)-f(x)]+[f(x-1)-f(x)]
\end{aligned}\]</div>
<p>一维函数其自由度可以理解为2，分别是+1方向和-1方向</p>
</li>
<li>
<p>二维</p>
<div class="arithmatex">\[\begin{aligned}
(\Delta f)_{i} &amp;=\sum_{j} \frac{\partial^{2} f_{i}}{\partial j^{2}} \approx \sum_{j \in N_{i}} a_{i j}\left(f_{i}-f_{j}\right) \\
&amp;=\sum_{j} a_{i j}\left(f_{i}-f_{j}\right)=\left(\sum_{j} a_{i j}\right) f_{i}-\sum_{j} a_{i j} f_{j} \\
&amp;=(D f)_{i}-(A f)_{i}=[(D-A) f]_{i}
\end{aligned}\]</div>
<ul>
<li>拉普拉斯算子就是在所有自由度上进行微小变化后获得的总增益。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>拉普拉斯矩阵:</strong> <span class="arithmatex">\(L = D-A\)</span>, 正则化的拉普拉斯矩阵：<span class="arithmatex">\(\hat{L} = D^{-\frac{1}{2}}LD^{\frac{1}{2}} = I-D^{-\frac{1}{2}}AD^{\frac{1}{2}}\)</span></p>
<ul>
<li>图拉普拉斯算子作用在由图节点信息构成的向量<span class="arithmatex">\(f\)</span>,得到的结果等于图拉普拉斯矩阵和向量<span class="arithmatex">\(f\)</span>的点积</li>
</ul>
</li>
</ul>
<h3 id="_10"><strong>图相关的矩阵规律</strong><a class="headerlink" href="#_10" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><span class="arithmatex">\(X\)</span>是节点本身的矩阵（考虑一维），<span class="arithmatex">\(A\)</span>是邻接矩阵，<span class="arithmatex">\(L\)</span>是拉普拉斯矩阵</p>
<ul>
<li><span class="arithmatex">\(Ax = [\sum_j a_{ij}x_{j}]\)</span>, 邻点总和</li>
<li><span class="arithmatex">\(X^TAX = \sum_i \sum_j a_{ij} x_i x_j\)</span>, 点对连乘相加</li>
<li><span class="arithmatex">\(LX = [\sum_j a_{ij}(x_i-x_j)]\)</span>, 邻点与自身差异总和</li>
<li>
<p><span class="arithmatex">\(X^{T} L X=X^{T}(D-A) X=X^{T} D X-X^{T} A X\)</span></p>
<div class="arithmatex">\[\begin{aligned}
X^{T} L X &amp;=\sum_{i=1}^{n} d_{i} x_{i}^{2}-\sum_{i=1}^{n} \sum_{j=1}^{n} a_{i j} x_{i} x_{j} \\
&amp;=\frac{1}{2}\left(\sum_{i=1}^{n} d_{i} x_{i}^{2}-2 \sum_{i=1}^{n} \sum_{j=1}^{n} a_{i j} x_{i} x_{j}+\sum_{j=1}^{n} d_{j} x_{j}^{2}\right) \\
&amp;=\frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n}\left(a_{i j} x_{i}^{2}-2 a_{i j} x_{i} x_{j}+a_{i j} x_{i}^{2}\right) \\
&amp;=\frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} a_{i j}\left(x_{i}-x_{j}\right)^{2} \geq 0
\end{aligned}\]</div>
</li>
<li>
<p>拉普拉斯是半正定矩阵。</p>
</li>
</ul>
</li>
<li>
<p><strong>拉普拉斯矩阵的谱分解：</strong> 拉普拉斯矩阵的谱分解就是特征分解。由于拉普拉斯矩阵是半正定对称矩阵，对其进行对角化处理，<span class="arithmatex">\(L = V \Lambda V^{-1} = V \Lambda V^{-T}\)</span>。根据半正定对称矩阵的特性，<span class="arithmatex">\(V\)</span>中的这些特征向量都是彼此的标准正交基。</p>
</li>
</ul>
<p><span id = "ref2" style="font-size:20px">Ref</span></p>
<ol>
<li>
<p><a href="https://zh.wikipedia.org/zh-hans/%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5">wiki，度矩阵</a></p>
</li>
<li>
<p><a href="http://web.ntnu.edu.tw/~algo/GraphSpectrum.html#2">ntnu，Graph_Spectrum</a></p>
</li>
<li>
<p><a href="http://xtf615.com/2019/02/24/gcn/">xtf615，图卷积神经网络理论基础</a></p>
</li>
<li>
<p>http://tkipf.github.io/</p>
</li>
</ol>
<h2 id="_11">傅里叶变换<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h2>
<p>傅里叶变换的公式：　</p>
<div class="arithmatex">\[
\hat{g}(f)=\int_{-\infty}^{+\infty} g(t) e^{-2 \pi i t f} d t
\]</div>
<ul>
<li>一个逆时针旋转360°画成的圆: <span class="arithmatex">\(e^{2 \pi i }\)</span></li>
<li>表示运动，需要原函数的自变量，时间<span class="arithmatex">\(t\)</span>: <span class="arithmatex">\(e^{2 \pi it}\)</span></li>
<li>表示旋转速度，需要自变量，频率<span class="arithmatex">\(f\)</span>: <span class="arithmatex">\(e^{2 \pi itf}\)</span></li>
<li>规定变换的采样方向为顺时针，加负号: <span class="arithmatex">\(e^{-2 \pi itf}\)</span></li>
<li>乘以原函数缠绕到单位圆并记录(此处使用<span class="arithmatex">\(g\)</span>符号标识原函数)： <span class="arithmatex">\(g(t)e^{-2 \pi itf}\)</span></li>
<li>为了计算质心特征<ul>
<li>取很多个点，求平均<span class="arithmatex">\(\frac{1}{N} \sum_{k=1}^{N} g\left(t_{k}\right) e^{-2 \pi i f t}\)</span></li>
<li>随着采样点的增加，需要使用积分来求解这个问题: <span class="arithmatex">\(\frac{1}{t_{2}-t_{1}} \int_{t_{1}}^{t_{2}} g(t) e^{-2 \pi i f t} d t\)</span></li>
<li>忽略系数，积分：<span class="arithmatex">\(\int_{-\infty}^{+\infty} g(t) e^{-2 \pi i t f} d t\)</span></li>
</ul>
</li>
<li>自变量为频率，写出函数表达式: <span class="arithmatex">\(\hat{g}(f)=\int_{-\infty}^{+\infty} g(t) e^{-2 \pi i t f} d t\)</span><ul>
<li>对于不同的频率<span class="arithmatex">\(f\)</span>，<span class="arithmatex">\(\hat{g}(f)\)</span>即为对应的傅里叶系数，其会有不同的取值。当<span class="arithmatex">\(\hat{g}(f)\)</span>比较大时，对应频率就是所求的单位函数的频率</li>
</ul>
</li>
</ul>
<p>我的理解是，傅里叶变换把复杂函数分解成单位函数（时域变频域）。傅里叶系数本质上在傅里叶基上的一种投影。  </p>
<table>
<thead>
<tr>
<th align="center">变换</th>
<th align="center">时间</th>
<th align="center">频率</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">连续傅里叶变换</td>
<td align="center">连续，非周期性</td>
<td align="center">连续，非周期性</td>
</tr>
<tr>
<td align="center">傅里叶级数</td>
<td align="center">连续，周期性</td>
<td align="center">离散，非周期性</td>
</tr>
<tr>
<td align="center"><strong>离散时间傅里叶变换</strong></td>
<td align="center"><strong>离散，非周期性</strong></td>
<td align="center"><strong>连续，周期性</strong></td>
</tr>
<tr>
<td align="center">离散傅里叶变换</td>
<td align="center">离散，周期性</td>
<td align="center">离散，周期性</td>
</tr>
</tbody>
</table>
<p>函数在时（频）域的离散对应于其像函数在频（时）域的周期性.反之连续则意味着在到达域的信号的非周期性.</p>
<p><span id = "ref３" style="font-size:20px">Ref</span>  </p>
<ol>
<li>
<p><a href="https://www.bilibili.com/video/av19141078/">3blue1brown,形象展示傅里叶变换</a>  </p>
</li>
<li>
<p><a href="https://charlesliuyx.github.io/2018/02/18/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E8%AE%A9%E4%BD%A0%E6%B0%B8%E8%BF%9C%E5%BF%98%E4%B8%8D%E4%BA%86%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E8%A7%A3%E6%9E%90/">charlesliuyx，让你永远忘不了的傅里叶变换解析</a></p>
</li>
<li>
<p><a href="https://zh.wikipedia.org/wiki/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2">wiki,傅里叶变换</a></p>
</li>
</ol>
<h2 id="gnn">GNN<a class="headerlink" href="#gnn" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th align="center">传统傅里叶变换</th>
<th align="center">图傅里叶变换</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">频率（<span class="arithmatex">\(f\)</span>）</td>
<td align="center">特征值（<span class="arithmatex">\(λ_k\)</span>）</td>
</tr>
<tr>
<td align="center">正弦函数(傅里叶基)（<span class="arithmatex">\(e^{−2\pi itf}\)</span>）</td>
<td align="center">特征向量(傅里叶基)（<span class="arithmatex">\(v_k\)</span>）</td>
</tr>
<tr>
<td align="center">转换后的振幅(傅里叶系数) <span class="arithmatex">\(\hat{g(f)}\)</span></td>
<td align="center">转换后的振幅(傅里叶系数)（<span class="arithmatex">\(\hat{x_k}\)</span>）</td>
</tr>
</tbody>
</table>
<p>图的傅里叶变换写作：<span class="arithmatex">\(\hat{x} = V^Tx\)</span>.<br />
图的逆傅里叶变换写作：<span class="arithmatex">\(x = V\hat{x}\)</span><br />
其中，<span class="arithmatex">\(V\)</span>为特征向量矩阵，<span class="arithmatex">\(x\)</span>为任意一个在图上的信号(节点信息构成的<span class="arithmatex">\(n\)</span>维向量)。这是一种对图信号的分解，图上的任意一个图信号都可以被表示成基向量的线性加权，具体来说，这边的权重就是图信号在对应傅里叶基上的傅里叶系数。</p>
<p>有了图的傅里叶变换以后，我们就可以改写用于表示图平滑度的总变差（total variation）:  </p>
<div class="arithmatex">\[
\begin{aligned}
TV(x) = x^TLx
&amp; = x^TV\Lambda V^Tx = (V\hat{x})^TV\Lambda V^T (V\hat{x}) \\
&amp; = \hat{x}^T V^T V\Lambda V^T V\hat{x} \\
&amp; = \hat{x}^T \Lambda \hat{x} = \sum_{k}^{N}\lambda_k\hat{x_k}^2
\end{aligned}
\]</div>
<p>这里可以发现，图信号的总变差与图的特征值之间有着非常直接的线性对应关系，总变差是图的所有特征值的一个线性组合，权重是图信号相对应的傅里叶系数的平方。特征值越低，频率越低，对应的傅里叶基就变化越缓慢，相近节点上的信号值趋于一致；特征值越高，频率越高，对应的傅里叶基就变化越剧烈，相近节点上的信号值则非常不一致。图信号在低频分量上的强度越大，该信号的平滑度就越高；相反，图信号在高频分量上的强度越大，该信号平滑度就越低。</p>
<p>图信号所有的傅里叶系数称为该信号的频谱。频谱考虑了图信号本身值的大小，也考虑了图的结构信息。</p>
<p><span id = "ref4" style="font-size:20px">Ref</span></p>
<ol>
<li>
<p><a href="http://xtf615.com/2019/02/24/gcn/GNN">xtf615,图卷积神经网络理论基础</a></p>
</li>
<li>
<p><a href="">深入浅出图卷积, P86-89</a></p>
</li>
</ol>
<h2 id="_12">图滤波器<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h2>
<p>图滤波器就是对给定图信号的频谱中各个频率分量的强度进行增强或减弱的操作。
假设图滤波器为<span class="arithmatex">\(H \in R^{N \times N}\)</span>，则<span class="arithmatex">\(H：R^N \rightarrow R^N\)</span>, 输出的图信号为<span class="arithmatex">\(y\)</span>:  </p>
<div class="arithmatex">\[
\begin{aligned}
y=Hx=\sum_{k=1}^{N}\left(h\left(\lambda_{k}\right) \tilde{x}_{k}\right) \boldsymbol{v}_{k}
&amp; =\left[
  \begin{array}{cccc}
  \vdots &amp; \vdots &amp; \cdots &amp; \vdots \\ 
  v_{1} &amp; v_{2} &amp; \cdots &amp; v_{N} \\ 
  \vdots &amp; \vdots &amp; \cdots &amp; \vdots
  \end{array}
  \right]
  \left[
    \begin{array}{c}
    h\left(\lambda_{1}\right) \tilde{x}_{1} \\ 
    h\left(\lambda_{2}\right) \tilde{x}_{2} \\ 
    \vdots \\ 
    h\left(\lambda_{N}\right) \tilde{x}_{N}
    \end{array}
  \right]
\\ &amp;= V\left[
    \begin{array}{cccc}h\left(\lambda_{1}\right) &amp; &amp; &amp; \\ 
    &amp; h\left(\lambda_{2}\right) &amp; &amp; \\
    &amp; &amp; \ddots &amp; \\ 
    &amp; &amp; &amp; h\left(\lambda_{N}\right)
    \end{array}
    \right]
    \left[\begin{array}{c}\tilde{x}_{1} \\ 
    \tilde{x}_{2} \\ 
    \vdots \\ 
    \tilde{x}_{N}
    \end{array}
    \right]
\\ &amp; = V\left[
  \begin{array}{cccc}h\left(\lambda_{1}\right) &amp; &amp; &amp; \\ 
  &amp; h\left(\lambda_{2}\right) &amp; &amp; \\ 
  &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; h
  \left(\lambda_{N}\right)
  \end{array}
  \right]
  V^Tx
\end{aligned}
\]</div>
<p>所以，<span class="arithmatex">\(H = V\left[\begin{array}{cccc}h\left(\lambda_{1}\right) &amp; &amp; &amp; \\ &amp; h\left(\lambda_{2}\right) &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; h\left(\lambda_{N}\right)\end{array}\right]V^T\)</span>, <span class="arithmatex">\(H\)</span>是对拉普拉斯矩阵特征值的改动。</p>
<p>通过逼近理论，我们可以运用泰勒展开-多项式逼近函数去近似任意函数，把图滤波器写成拉普拉斯矩阵多项式拓展形式：  </p>
<div class="arithmatex">\[
H=h_{0} L^{0}+h_{1} L^{1}+h_{2} L^{2}+\cdots+h_{K} L^{K}=\sum_{k=0}^{K} h_{k} L^{k}
\]</div>
<p>其中<span class="arithmatex">\(k\)</span>是图滤波器<span class="arithmatex">\(H\)</span>的阶数.</p>
<h3 id="_13">频域角度理解<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h3>
<ul>
<li>滤波器:</li>
</ul>
<div class="arithmatex">\[
H=\sum_{k=0}^{K} h_{k} L^{k}
=\sum_{k=0}^{K} h_{k}\left(V \Lambda V^{T}\right)^{k}
=V\left(\sum_{k=0}^{K} h_{k} \Lambda^{k}\right) V^{T} 
= V\left[
  \begin{array}{ccc}\sum_{i=0}^{K} h_{k} \lambda_{1}^{k} &amp; \\ 
  &amp; \ddots \\ 
  &amp; \sum_{k=0}^{K} h_{k} \lambda_{N}^{k}
  \end{array}
  \right] V^{T}
\]</div>
<ul>
<li><span class="arithmatex">\(H\)</span>的频率响应矩阵：<span class="arithmatex">\(\Lambda_h = \sum_{k=0}^{K} h_{k} \Lambda^{k} = = diag(\Psi \boldsymbol{h})\)</span></li>
</ul>
<p><span class="arithmatex">\(\boldsymbol{h}\)</span>为多项式系数<span class="arithmatex">\(h\)</span>构成的向量，<span class="arithmatex">\(\Psi\)</span> 为范德蒙矩阵</p>
<div class="arithmatex">\[\left[\begin{array}{cccc}
1 &amp; \lambda_{1} &amp; \cdots &amp; \lambda_{1}^{K} \\
1 &amp; \lambda_{2} &amp; \cdots &amp; \lambda_{2}^{K} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; \lambda_{N} &amp; \cdots &amp; \lambda_{N}^{K}
\end{array}\right]\]</div>
<p>我们可以反解得到多项式系数 <span class="arithmatex">\(\boldsymbol{h}=\Psi^{-1} \operatorname{diag}^{-1}\left(\Lambda_{h}\right)\)</span>。 </p>
<ul>
<li>
<p>滤波操作: </p>
<div class="arithmatex">\[
y = Hx = V\left(\sum_{k=0}^{K} h_{k} \Lambda^{k}\right) V^{T}x
\]</div>
</li>
<li>
<p>通过图傅里叶变换，即<span class="arithmatex">\(V^Tx\)</span>将图信号变换到频域空间</p>
</li>
<li>通过<span class="arithmatex">\(\Lambda^{k} = \sum_{k=0}^{K} h_{k} \Lambda^{k}\)</span>对频率分量的强度进行调节，得到<span class="arithmatex">\(\tilde{y}\)</span></li>
<li>通过逆图傅里叶变换，即<span class="arithmatex">\(V\tilde{y}\)</span>将<span class="arithmatex">\(\tilde{y}\)</span>反解成图信号<span class="arithmatex">\(y\)</span></li>
</ul>
<h3 id="_14">空域角度理解<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h3>
<p>对于 <span class="arithmatex">\(y=H x=\sum_{i=0}^{K} h_{k} L^{k} x\)</span>，设定
<span class="arithmatex">\(\boldsymbol{x}^{(k)}=L^{k} \boldsymbol{x}=L \boldsymbol{x}^{(k-1)}\)</span>，即 <span class="arithmatex">\(x^{k–1}\)</span>到<span class="arithmatex">\(x^{k}\)</span>的变换只需要所有节点的一阶邻居参与计算.
那么  </p>
<div class="arithmatex">\[y=H x=\sum_{i=0}^{K} h^{k} x^{k}\]</div>
<p>总的来看，<span class="arithmatex">\(x^{k}\)</span>的计算只需要所有节点的<span class="arithmatex">\(k\)</span>阶邻居参与。这就体现了图滤波器的局部性。</p>
<p>从空域角度来看，滤波操作具有以下性质：</p>
<ul>
<li>可通过<span class="arithmatex">\(K\)</span>步迭代式的矩阵向量乘法来完成滤波操作。</li>
<li>具有局部性，每个节点的输出信号值只需要考虑其<span class="arithmatex">\(K\)</span>阶子图；</li>
</ul>
<h3 id="_15">频域与空域比较<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h3>
<ul>
<li>对矩阵进行特征分解是一个非常耗时的操作，具有<span class="arithmatex">\(O(N^3)\)</span>的时间复杂度，相比空域视角中的矩阵向量乘法而言，有工程上的局限性。</li>
<li>频谱方法是空间方法的特例。（有显示空间的就叫谱方法 （用傅里叶变换就是把矩阵投射到拉普拉斯矩阵特征向量张成的空间），没有显示空间的就叫空间方法 <a href="#沈华伟">2</a> ）</li>
</ul>
<p><span id = "ref5" style="font-size:20px">Ref</span></p>
<ol>
<li>
<p><a href="https://www.bilibili.com/video/BV1ta4y1t7EK">沈华伟，图卷积神经网络</a>  </p>
</li>
<li>
<p><a href="">深入浅出图卷积, P93-96</a></p>
</li>
</ol>
<h2 id="_16">图卷积<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h2>
<p>GCN的基本思想： 把一个节点在图中的高纬度邻接信息降维到一个低维的向量表示<br />
GCN的优点： 可以捕捉graph的全局信息，从而很好地表示node的特征。<br />
GCN的缺点： </p>
<ul>
<li>Transductive learning的方式，需要把所有节点都参与训练才能得到node embedding，无法快速得到新node的embedding。这样的话，就无法完成inductive任务，即处理动态图问题。inductive任务是指：训练阶段与测试阶段需要处理的graph不同。通常是训练阶段只是在子图（subgraph）上进行，测试阶段需要处理未知的顶点。（unseen node）</li>
<li>处理有向图的瓶颈，不容易实现分配不同的学习权重给不同的neighbor</li>
<li>有过平滑的风险</li>
</ul>
<p>两组图信号的图卷积运算总能转化为对应形式的图滤波运算，从这个层面上来看，图卷积等价于图滤波。</p>
<ul>
<li>对频率响应矩阵进行参数化 <a href="#chebynet">1</a></li>
<li>对多项式系数进行参数化 <a href="#GCN">2</a></li>
<li>该网络可以有效地对节点的一阶邻居进行处理，而且可以避免复杂的矩阵运算</li>
<li>设计固定的图滤波器</li>
</ul>
<h3 id="gcncnn">GCN与CNN的比较<a class="headerlink" href="#gcncnn" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>聚合邻域信息</p>
<ul>
<li>GCN　非结构化数据</li>
<li>CNN　结构化数据</li>
</ul>
</li>
<li>
<p>局部连接</p>
<ul>
<li>节点下一层的特征计算只依赖于自身领域</li>
<li>CNN的卷积核设计了９组权重参数，GCN的退化为一组</li>
</ul>
</li>
<li>
<p>卷积核的权重处处共享，作用于所有节点</p>
</li>
<li>感受域随着卷积层的增加而增大</li>
</ul>
<h3 id="gcn">GCN与基于手工与基于随机游走的方法的比较<a class="headerlink" href="#gcn" title="Permanent link">&para;</a></h3>
<p>图的信息：节点信息、结构信息</p>
<ul>
<li>
<p>基于手工：结构特征依赖人工干预。将节点信息和结构信息拼接</p>
</li>
<li>
<p>随机游走：将图中节点所满足的关系与结构的性质映射到一个新的向量空间。将节点信息和结构信息拼接</p>
</li>
<li>
<p>GCN：迭代式地聚合邻居节点的特征，从而更新当前节点的特征。【端到端】</p>
<ul>
<li>参数更新及时，节点的特征表示与下游任务之间具有更好的适应性</li>
<li>对结构信息与属性信息的学习同时进行，没有拆分和解构。而这两者往往有很好的互补关系</li>
</ul>
</li>
</ul>
<h3 id="gcn_1">GCN是一个低通滤波器<a class="headerlink" href="#gcn_1" title="Permanent link">&para;</a></h3>
<p>损失函数中的正则项越小，使得相邻节点的分类标签趋于一致，可以使我们更高效地对未标记的数据进行学习。而越减小该项，表示经过模型之后的图信号越平滑，从频域角度看，相当于对图信号做了低通滤波器处理。</p>
<ul>
<li>低通滤波可以对数据进行有效去噪</li>
<li>低频的波段已经蕴含了大部分信息</li>
</ul>
<h3 id="gcn_2">GCN的过平滑问题<a class="headerlink" href="#gcn_2" title="Permanent link">&para;</a></h3>
<p>但是GNN不想CNN可以多层堆叠，因为多次对信号进行平滑操作后，信号会越来越趋同，也就丧失了节点特征的多样新，出现“过平滑”问题。
- 频域角度：多次堆叠后，有些特征向量会处处相等，趋同了
- 空域角度：层数过多，每个节点能覆盖到的节点都会收敛到全图节点。这会大大降低每个节点的局部网络的多样性，对于节点自身的特征学习十分不利。</p>
<p>如何解决：</p>
<ul>
<li>自适应聚合半径: 通过增加跳跃连接来聚合模型的每层节点输出，聚合后的节点特征拥有混合的聚合半径</li>
</ul>
<h3 id="gcn_3">GCN实战<a class="headerlink" href="#gcn_3" title="Permanent link">&para;</a></h3>
<p>https://github.com/FighterLYL/GraphNeuralNetwork/tree/master/chapter5</p>
<p><span id = "ref5" style="font-size:20px">Ref</span></p>
<ol>
<li>
<p><span id = "chebynet"></span><a href="https://arxiv.org/pdf/1606.09375.pdf">Convolutional Neural Networks on Graphs
with Fast Localized Spectral Filtering</a></p>
</li>
<li>
<p><a href="">深入浅出图卷积, P97-100</a></p>
</li>
<li>
<p><span id = "GCN"></span><a href="https://arxiv.org/abs/1609.02907">Semi-Supervised Classification with Graph Convolutional Networks</a></p>
</li>
<li>
<p><a href="">深入浅出图卷积, P112-127</a></p>
</li>
<li>
<p><a href="https://blog.csdn.net/yyl424525/article/details/100532849">[论文笔记]：GraphSAGE：Inductive Representation Learning on Large Graphs</a></p>
</li>
</ol>
                
                  
                    

<hr>
<div class="md-source-date">
  <small>
    
      Last update: 2021-01-23
    
  </small>
</div>
                  
                
              

  
    <div class="md-source-date">
      <small>
          Author:
          
          <span>
              wbq
          </span>
          
      </small>
    </div>
  
 
<!-- <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_page_pv"></span>次</span> -->

              
                


  <h2 id="__comments">Comments</h2>
  <div id="disqus_thread"></div>
  <script>var disqus_config=function(){this.page.url="https://github.com/SkrLamei/blog/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GNN/",this.page.identifier="/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/GNN/"};window.addEventListener("load",function(){var e=document,i=e.createElement("script");i.src="//binqingwu.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(i)})</script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../../AI%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%8C%83%E6%95%B0%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96/" title="范数与正则化" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                范数与正则化
              </div>
            </div>
          </a>
        
        
          <a href="../../%E6%A6%82%E7%8E%87%E7%9B%B8%E5%85%B3/ACD/" title="ACD" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                ACD
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Lamei
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.2d1db4bd.min.js"></script>
      <script src="../../assets/javascripts/bundle.6627ddf3.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: ['navigation.tabs', 'navigation.tabs.sticky'],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.5eca75d3.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdn.bootcdn.net/ajax/libs/mathjax/3.1.0/es5/tex-mml-chtml.min.js"></script>
      
    
  </body>
</html>