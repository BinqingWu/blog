# 概率基础

学习的课程：Probabilistic Systems Analysis and Applied Probability

OCW原地址: http://ocw.mit.edu/6-041SCF13

额外习题：《概率论与数理统计习题全解指南》.浙大版（第四版）

## 1	Probability Models and Axioms

- Sample space $\Omega$
  - Mutually exclusive 可能输出之间没有重合部分
  - Collectively exhaustive 所有可能输出都包括了
  - Right granularity 根据实际情况选择正确的样本空间
- Event: Subset of the sample space
- If $A_1, A_2,\dots$ are disjoint events (交一交为空), then: $P(A_1 \cup A2 \cup \dots ) = P(A_1) + P(A_2) + \dots$

## 2	Conditioning and Bayes' Rule

Confitional probalility: Assuming $P(B) \neq 0$, $P(A|B) = \frac{P(A \cap B)}{P(B)}$

- Multiplication rule: $P(A \cap B) = P(B) \cdot P(A | B) = P(A) · P(B | A)$
- Total probability theorem: $P(B) = P(A)P(B|A) + P(A^c)P(B|A^c)$
- Bayes rule: $P(A_i | B) = \frac{P(A_i \cap B)}{P(B)} = \frac{ P(A_i) \cdot P(B|A_i) }{P(B)} = \frac{ P(A_i) \cdot P(B | A_i) }{\sum_{j}P(A_j)P(B|A_j)}$

## 3	Independence

- $P(B|A) = P(B)$，或者$P(A\cap B) = P(A) \cdot P(B)$
- 推论$P(A_i \cap A_j \cap \dots \cap A_q) = P(A_i)P(A_j) \dots P(A_q)$

注意区分disjoint和independent：

- disjoint: 两个事件不可能同时成立，A发生B一定不发生，B发生A一定不发生
- independent: B事件发生与否，对A事件没影响

conditioning may affect independence

Pairwise independence does not imply independence：若A和B independent，B和C independent，不能保证A、B、C三者independent

## 4	Counting

Discrete uniform law：$P(A) = \frac{|A|}{|\Omega|}$

- Basic counting principle：

  - 加法原理：如果某件事可以由 k 类不同途径之一去完成，在第一类途径中有 m1 中完成方法，在第二类途径中有 m2，第 k 类途径中有 mk 种完成的方法，那么完成这件事总共有 m1+m2+…+mk 中方法。
  - 乘法原理：如果某件事需经过 k 个步骤才能完成，做第一步有 m1 种方法，做第二步有 m2 种方法，…..，做第 k 步有 mk 种方法，那么完成这件事总共有 m1×m2×…×mk 种方法。
- 排列：从 n 个不同元素中任意取 r(r $\leq$ n) 个元素排成一列（**考虑元素先后出现的次序**），称此为一个排列，此种排列的总数记为 $P_n^r$。按照乘法原理，取出的第一个元素有 n 种取法，取出的第二个元素有 n−1 种取法，……，取出第 r 个元素有 n−r+1 种取法，所以有 $P^r_n = n \times (n - 1) \times \ldots \times (n - r + 1) = \frac{n!}{(n-r)!}$
- 组合：从 n 个不同元素中任意取 r(r $\leq$ n) 个元素并成一组（不考虑元素间的先后次序），称此为一个组合，此中组合的总数记为 $\binom{n}{r}$ 或 $C_n^r$。按照乘法原理中组合的总数为 $\binom{n}{r} = \frac{P^r_n}{r!} = \frac{n(n - 1) \dots (n - r + 1)}{r!} = \frac{n!}{r!\phantom{1}(n-r)!}$
- $P^r_n = r! \times \binom{n}{r}$
- $\sum_{k=0}^{n} \binom{n}{k} = 2^n$, 和｛ 1,2,...,n｝有多少个子集问题一样
- Binomial probabilities: $\binom{n}{k}p^k(1-p)^{n-k}$

## 5	Discrete Random Variables; Probability Mass Functions; Expectations; Variance

- Random Variables $X$:  A function from the sample space $\Omega$ to the real numbers

- Probability mass function: “probability distribution” of $X$

$p_X(x) = P(X=x) =P({\omega \in \Omega s.t. X(\omega) = x})$

$p_X(x) \geq 0$, $\sum_xp_X(x) = 1$ (如果加起来不为1，那就不是valid PMF了)

- Expectation:

$E[X] = \sum_xxp_X(x)$ Interpretations: Center of gravity of PMF

Let $X$ be a r.v. and let $Y = g(X)$

根据定义，$E[Y] = \sum_yyp_Y(y)$, 但是计算困难。替代计算：$E[Y] = \sum_xg(x)p_X(x)$

原来的视角站在y中，现在的视角站在x中，是把y看成是x的某种映射，

通常来说，$E[g(X)] \neq g(E[X])$, 但是当$g(.)$是linear的时候，是相等的

- Variance: $var(X) = E[(X-E[X])^2] = \sum_x(x-E[x])^2p_X(x) = E[X^2] - (E[X])^2$

$var(\alpha X+\beta) = \alpha^2 var(X)$

## 6	Discrete Random Variable Examples; Joint PMFs

- Conditional PMF and expectation

$p_{X|A}(x) = P(X=x|A) $

$E[X|A] = \sum_xxp_{X|A}(x)$

- Geometric PMF

![image-20210224111446994](/home/wbq/.config/Typora/typora-user-images/image-20210224111446994.png)

注意第二幅图的rescale， 3对上去的地方不是$p(1-p)^3$ 而是$p$；第三幅图是第二幅图的平移结果。

- Total Expectation theorem

![image-20210224113004371](/home/wbq/.config/Typora/typora-user-images/image-20210224113004371.png)

> $E[X] = P(X=1)E[X|X =1] + P(X>1)E[X|X>1]$,求$E[X]$ 

- Joint PMFs

$\sum_x \sum_y p_{X,Y}(x,y) = 1$

$p_X(x) = \sum_y p_{X,Y}(x,y)$, 在$X=x$的前提下，取遍所有可能的$y$

$p_{X|Y}(x|y) = P(X=x|Y=y) = \frac{P_{X,Y}(x,y)}{P_Y(y)}$

$\sum_x p_{X|Y}(x|y) = 1$, $Y=y$ 前提下所有x都取遍，相当于rescale了PMF一下，概率总和还是1

## 7	Multiple Discrete Random Variables: Expectations, Conditioning, Independence

- Independence

- Expectations

  $E[g(X,Y)] = \sum_x \sum_y g(x,y)p_{X,Y}(x,y)$

  通常情况下，$E[g(X,Y)] \neq g(E[X],E[Y])$ ，除非$g(X,Y)$是线性的，或者$X,Y$ 独立

- Conditioning

- Binomial mean and variance

![image-20210224192927216](/home/wbq/.config/Typora/typora-user-images/image-20210224192927216.png)

## 8	Continuous Random Variables





## 9	Multiple Continuous Random Variables
## 10	Continuous Bayes' Rule; Derived Distributions
## 11	Derived Distributions; Convolution; Covariance and Correlation
## 12	Iterated Expectations; Sum of a Random Number of Random Variables
## 13	Bernoulli Process
## 14	Poisson Process - I
## 15	Poisson Process - II
## 16	Markov Chains - I
## 17	Markov Chains - II
## 18	Markov Chains - III
## 19	Weak Law of Large Numbers
## 20	Central Limit Theorem
## 21	Bayesian Statistical Inference - I
## 22	Bayesian Statistical Inference - II
## 23	Classical Statistical Inference - I
## 24	Classical Inference - II
## 25	Classical Inference - III; Course Overview