# 概率基础

学习的课程：Probabilistic Systems Analysis and Applied Probability

OCW原地址: http://ocw.mit.edu/6-041SCF13

## 1	Probability Models and Axioms

- Sample space $\Omega$
  - Mutually exclusive 可能输出之间没有重合部分
  - Collectively exhaustive 所有可能输出都包括了
  - Right granularity 根据实际情况选择正确的样本空间
- Event: Subset of the sample space
- If $A_1, A_2,\dots$ are disjoint events (交一交为空), then: $P(A_1 \cup A2 \cup \dots ) = P(A_1) + P(A_2) + \dots$

## 2	Conditioning and Bayes' Rule

Definition of confitional probalility:

Assuming $P(B) \neq 0$, $P(A|B) = \frac{P(A \cap B)}{P(B)}$

- Multiplication rule: $P(A \cap B) = P(B) \cdot P(A | B) = P(A) · P(B | A)$
- Total probability theorem: $P(B) = P(A)P(B|A) + P(A^c)P(B|A^c)$
- Bayes rule: $P(A_i | B) = \frac{P(A_i \cap B)}{P(B)} = \frac{ P(A_i) \cdot P(B|A_i) }{P(B)} = \frac{ P(A_i \cdot P(A_i | B) }{\sum_{j}P(A_j)P(B|A_j)}$

## 3	Independence

- $P(B|A) = P(B)$
- 或者$P(A\cap B) = P(A) \cdot P(B)$
- 推论$P(A_i \cap A_j \cap \dots \cap A_q) = P(A_i)P(A_j) \dots P(A_q)$

注意区分disjoint和independent：

- disjoint: 两个事件不可能同时成立，A发生B一定不发生，B发生A一定不发生
- independent: B事件发生与否，对A时间没影响

conditioning may affect independence

Pairwise independence does not imply independence：若A和B independent，若B和C independent，不能保证A、B、C三者independent

## 4	Counting

Discrete uniform law：$P(A) = \frac{|A|}{|\Omega|}$

- Basic counting principle：

  - 加法原理：如果某件事可以由 k 类不同途径之一去完成，在第一类途径中有 m1 中完成方法，在第二类途径中有 m2，第 k 类途径中有 mk 种完成的方法，那么完成这件事总共有 m1+m2+…+mk 中方法。
  - 乘法原理：如果某件事需经过 k 个步骤才能完成，做第一步有 m1 种方法，做第二步有 m2 种方法，…..，做第 k 步有 mk 种方法，那么完成这件事总共有 m1×m2×…×mk 种方法。
- 排列：从 n 个不同元素中任意取 r(r $\leq$ n) 个元素排成一列（**考虑元素先后出现的次序**），称此为一个排列，此种排列的总数记为 $P_n^r$。按照乘法原理，取出的第一个元素有 n 种取法，取出的第二个元素有 n−1 种取法，……，取出第 r 个元素有 n−r+1 种取法，所以有 $P^r_n = n \times (n - 1) \times \ldots \times (n - r + 1) = \frac{n!}{(n-r)!}$
- 组合：从 n 个不同元素中任意取 r(r $\leq$ n) 个元素并成一组（不考虑元素间的先后次序），称此为一个组合，此中组合的总数记为 $\binom{n}{r}$ 或 $C_n^r$。按照乘法原理中组合的总数为 $\binom{n}{r} = \frac{P^r_n}{r!} = \frac{n(n - 1) \dots (n - r + 1)}{r!} = \frac{n!}{r!\phantom{1}(n-r)!}$
- $P^r_n = r! \times \binom{n}{r}$
- $\sum_{k=0}^{n} \binom{n}{k} = 2^n$, 和｛ 1,2,...,n｝有多少个子集问题一样
- Binomial probabilities: $\binom{n}{k}p^k(1-p)^{n-k}$

## 5	Discrete Random Variables; Probability Mass Functions; Expectations; Variance

- Random Variables: (Mathematically) A function from the sample space $\Omega$ to the real numbers

- Probability mass function: 

$p_X(x) = P(X=x) =P({\omega \in \Omega s.t. X(\omega) = x})$

$p_X(x) \geq 0$, $\sum_xp_X(x) = 1$

- Expectation:

$E[X] = \sum_xxp_X(x)$

Let $X$ be a r.v. and let $Y = g(X)$

根据定义，$E[Y] = \sum_yyp_Y(y)$, 但是计算困难。替代计算：$E[Y] = \sum_xg(x)p_X(x)$

原来的视角站在y中，现在的视角是把y看成是x的某种映射

通常来说，$E[g(X)] \neq g(E[X])$, 但是当$g(.)$是linear的时候，是相等的

- Variance: $var(X) = E[(X-E[X])^2] = \sum_x(x-E[x])^2p_X(x) = E[X^2] - (E[X])^2$

$var(\alpha X+\beta) = \alpha^2 var(X)$

## 6	Discrete Random Variable Examples; Joint PMFs





## 7	Multiple Discrete Random Variables: Expectations, Conditioning, Independence

## 8	Continuous Random Variables
## 9	Multiple Continuous Random Variables
## 10	Continuous Bayes' Rule; Derived Distributions
## 11	Derived Distributions; Convolution; Covariance and Correlation
## 12	Iterated Expectations; Sum of a Random Number of Random Variables
## 13	Bernoulli Process
## 14	Poisson Process - I
## 15	Poisson Process - II
## 16	Markov Chains - I
## 17	Markov Chains - II
## 18	Markov Chains - III
## 19	Weak Law of Large Numbers
## 20	Central Limit Theorem
## 21	Bayesian Statistical Inference - I
## 22	Bayesian Statistical Inference - II
## 23	Classical Statistical Inference - I
## 24	Classical Inference - II
## 25	Classical Inference - III; Course Overview